# -*- coding: utf-8 -*-
"""SOI2023036299_Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZXRRvVvv7evmu_sBHgf1eiTMk8XB_d1P

SOI1010_Machine_Learning_II___Assignment_1_2025
"""

import torch
from torchvision import datasets

trainset = datasets.MNIST(root='./data',train=True, download=True)

testset = datasets.MNIST(root='./data',train=False,download=True)

torch.manual_seed(0)
val_ratio = 0.1
train_size = len(trainset)
indices = torch.randperm(train_size)
split_idx = (int)(train_size * val_ratio)

train_idx = indices[split_idx:]
val_idx = indices[:split_idx]

train_data = trainset.data[train_idx].float()/255.
train_labels = trainset.targets[train_idx]
val_data = trainset.data[val_idx].float()/255.
val_labels = trainset.targets[val_idx]
test_data = testset.data.float()/255.
test_labels = testset.targets

#Problem (a)
tmp_idx = 42 # 42 in the val's range.
tmp_image = val_data[tmp_idx]
tmp_labels = val_labels[tmp_idx]
pair_list = [] # (거리, 라벨) 저장.
for i in range(len(train_data)):
  now_image = train_data[i]
  now_labels = train_labels[i]
  distance = torch.sum((tmp_image-now_image)**2) #sqrt는 단조증가 함수라서 씌우지 않는다.
  pair_list.append((distance.item(),now_labels.item()))

sorted_list = sorted(pair_list, key=lambda pair:pair[0])

print("result \n")
print(sorted_list[:5])

def give_label(info: list):
  counting = {}
  for distance, label in info:
    if distance == 0:
      return label
    counting[label] = counting.get(label,0) + 1

  maximum = max(counting.values())

  nominate = []

  for label,count in counting.items():
    if count == maximum:
      nominate.append(label)

  if len(nominate) == 1:
    return nominate[0]

  else:
    check_winner = {}
    for distance, label in info:
      if label in nominate:
        check_winner[label] = check_winner.get(label,0) + 1/distance

    return max(check_winner, key=check_winner.get)
print(give_label(sorted_list[:5]))

#Problem(b)
image_for_test = val_data[42]
print(image_for_test.shape)
plus_dimension = image_for_test.unsqueeze(0)
print(plus_dimension.shape)

print(train_data.shape)

distance = torch.sum((train_data-plus_dimension)**2,dim=1).sum(dim=1)
print(distance.shape)

small_distance, index = torch.topk(distance,k=5,largest=False)

print(small_distance)
print(train_labels[index])

#Problem(c)
print(val_data.shape)
print(train_data.shape)

broad_val = val_data.unsqueeze(1)
broad_train = train_data.unsqueeze(0)
print(broad_val.shape)
print(broad_train.shape)

#distance = torch.sum((broad_val-broad_train)**2,dim=2).sum(dim=2)

#Problem(d)

br_val = val_data.view(6000,-1)
br_tr = train_data.view(54000,-1)

total_distance = torch.cdist(br_val,br_tr,p=2)**2

print(total_distance.shape)

result = []
for row in total_distance:
  pair_list = []
  for i in range(0,54000):
    pair_list.append((row[i],train_labels[i]))
  now_sort = sorted(pair_list, key=lambda pair:pair[0])
  result.append(give_label(now_sort[:5]))

print(result)

distance_info, idx = torch.topk(total_distance,k=5,dim=1,largest=False)

labels = train_labels[idx]

print(labels.shape)

results, _ = torch.mode(labels,dim=1)

print(results.shape)
print(_.shape)

print(results)
print(val_labels[_])
print(_)

print(results[42])
print(give_label(sorted_list[:5]))

#Probelm(E): We can control val_ratio and number of k
#Problem(F):

best_comb = []

for i in range(1,31):
  now_ratio = 0.01 * i

  split_idx = int(train_size * now_ratio)

  train_idx = indices[split_idx:]
  val_idx = indices[:split_idx]

  train_data = trainset.data[train_idx].float() / 255.
  train_labels = trainset.targets[train_idx]
  val_data = trainset.data[val_idx].float() / 255.
  val_labels = trainset.targets[val_idx]

  num_val = len(val_data)
  num_train = len(train_data)

  br_val = val_data.view(num_val, -1)
  br_tr = train_data.view(num_train,-1)

  total_distance = torch.cdist(br_val,br_tr,p=2)**2

  k_range = range(5,21)
  results_k = {}

  for k in k_range:
    _, idx = torch.topk(total_distance, k=k,dim=1, largest=False)
    labels = train_labels[idx]
    predictions, _ = torch.mode(labels,dim=1)
    accuracy = (predictions == val_labels).float().mean()

    results_k[k] = {'accuracy':accuracy.item()}

  best_k = max(results_k,key=lambda k: results_k[k]['accuracy'])
  best_comb.append({
    'ratio':now_ratio,'best_k':best_k,'accuracy':results_k[best_k]['accuracy']
})

  print(f"Ratio:{now_ratio}, k:{best_k}, Accuracy:{results_k[best_k]['accuracy']}")

Best = max(best_comb,key=lambda A: A['accuracy'])

final_ratio = Best['ratio']
final_k = Best['best_k']

print(f"Ratio:{final_ratio}, k:{final_k}")

best_k = 7

train_data = trainset.data.float() / 255.
train_labels = trainset.targets

test_data = testset.data.float()/255.
test_labels = testset.targets

num_train = len(train_data)
num_test = len(test_data)
br_train = train_data.view(num_train,-1)
br_test = test_data.view(num_test,-1)

total_distance = torch.cdist(br_test,br_train,p=2)**2

_, idx = torch.topk(total_distance, k = best_k, dim = 1, largest=False)
labels = train_labels[idx]
predictions, _  = torch.mode(labels, dim=1)

accuracy = (predictions == test_labels).float().mean()

print(f"k:{best_k}, accuracy:{accuracy}")

#Problem(G): Change Accuracy Algorithm.
#Instead of Accuracy, I will use F1 Score.

best_combination = []

for i in range(1,31): # After accuracy exceeded 30, acc dropped below 97%, so only proceeded up to 30.
  now_ratio = 0.01 * i

  split_idx = int(train_size * now_ratio)

  train_idx = indices[split_idx:]
  val_idx = indices[:split_idx]

  train_data = trainset.data[train_idx].float() / 255.
  train_labels = trainset.targets[train_idx]
  val_data = trainset.data[val_idx].float() / 255.
  val_labels = trainset.targets[val_idx]

  num_val = len(val_data)
  num_train = len(train_data)

  br_val = val_data.view(num_val, -1)
  br_tr = train_data.view(num_train,-1)

  total_distance = torch.cdist(br_val,br_tr,p=2)**2

  k_range = range(5,21)

  results_k = {}
  epsilon = 1e-8

  for k in k_range:

    _, idx = torch.topk(total_distance,k=k,dim=1,largest=False)
    labels = train_labels[idx]
    predictions, _  = torch.mode(labels, dim=1)

    f1_scores = []

    for c in range(10):
      positive_number = c

      tp = ((predictions == positive_number)&(val_labels == positive_number)).sum().float()
      fp = ((predictions == positive_number)&(val_labels != positive_number)).sum().float()
      fn = ((predictions != positive_number)&(val_labels == positive_number)).sum().float()

      precision = tp / (tp + fp + epsilon)
      recall = tp / (tp + fn + epsilon)
      f1_score =  2 * (precision * recall) / (precision + recall + epsilon)

      f1_scores.append(f1_score)

    total_f1 = torch.stack(f1_scores).mean()

    results_k[k] = {'f1_score':total_f1.item()}

  best_k = max(results_k, key=lambda k :results_k[k]['f1_score'])
  best_combination.append({
      'ratio':now_ratio,
      'best_k':best_k,
      'f1_score':results_k[best_k]['f1_score']
  })

  print(f"Ratio :{now_ratio}, Best k: {best_k}, F1:{results_k[best_k]['f1_score']}")


Best = max(best_combination,key=lambda A: A['f1_score'])

print(f"Ratio:{Best['ratio']}, K:{Best['best_k']},F1:{Best['f1_score']}")

final_ratio = Best['ratio']
final_k = Best['best_k']

#2. k = 7, F1 Score

best_k = 7
epsilon = 1e-8

train_data = trainset.data.float() / 255.
train_labels = trainset.targets

test_data = testset.data.float()/255.
test_labels = testset.targets

num_train = len(train_data)
num_test = len(test_data)
br_train = train_data.view(num_train,-1)
br_test = test_data.view(num_test,-1)

total_distance = torch.cdist(br_test,br_train,p=2)**2

_, idx = torch.topk(total_distance, k = best_k, dim = 1, largest=False)
labels = train_labels[idx]
predictions, _  = torch.mode(labels, dim=1)

f1_scores = []

for c in range(10):
  positive_number = c

  tp = ((predictions==positive_number)&(test_labels==positive_number)).sum().float()
  fp = ((predictions==positive_number)&(test_labels!=positive_number)).sum().float()
  fn = ((predictions!=positive_number)&(test_labels==positive_number)).sum().float()
  tn = ((predictions!=positive_number)&(test_labels!=positive_number)).sum().float()

  precision = tp/(tp+fp+epsilon)
  recall = tp / (tp+fn+epsilon)
  f1_score = 2 * (precision * recall) / (precision + recall + epsilon)

  f1_scores.append(f1_score)

final_test_f1 = torch.stack(f1_scores).mean()

print(f"k:{best_k},F1:{final_test_f1}")

#Additionally, Accuracy and F1 Score were measured with k=5, which recorded the next best performance after k=7.
best_k = 5
epsilon = 1e-8

train_data = trainset.data.float() / 255.
train_labels = trainset.targets

test_data = testset.data.float()/255.
test_labels = testset.targets

num_train = len(train_data)
num_test = len(test_data)
br_train = train_data.view(num_train,-1)
br_test = test_data.view(num_test,-1)

total_distance = torch.cdist(br_test,br_train,p=2)**2

_, idx = torch.topk(total_distance, k = best_k, dim = 1, largest=False)
labels = train_labels[idx]
predictions, _  = torch.mode(labels, dim=1)

f1_scores = []

for c in range(10):
  positive_number = c

  tp = ((predictions==positive_number)&(test_labels==positive_number)).sum().float()
  fp = ((predictions==positive_number)&(test_labels!=positive_number)).sum().float()
  fn = ((predictions!=positive_number)&(test_labels==positive_number)).sum().float()
  tn = ((predictions!=positive_number)&(test_labels!=positive_number)).sum().float()

  precision = tp/(tp+fp+epsilon)
  recall = tp / (tp+fn+epsilon)
  f1_score = 2 * (precision * recall) / (precision + recall + epsilon)

  f1_scores.append(f1_score)

final_test_f1 = torch.stack(f1_scores).mean()
accuracy = (predictions==test_labels).float().mean()
print(f"k:{best_k},F1:{final_test_f1},Acc:{accuracy}")

'''
k:5,F1:0.9687143564224243,Acc:0.9688000082969666
k:7,F1:0.9693803787231445,accuracy:0.9693999886512756
'''

best_k = 7
epsilon = 1e-8

train_data = trainset.data.float() / 255.
train_labels = trainset.targets

test_data = testset.data.float()/255.
test_labels = testset.targets

num_train = len(train_data)
num_test = len(test_data)
br_train = train_data.view(num_train,-1)
br_test = test_data.view(num_test,-1)

total_distance = torch.cdist(br_test,br_train,p=2)**2

_, idx = torch.topk(total_distance, k = best_k, dim = 1, largest=False)
labels = train_labels[idx]
predictions, _  = torch.mode(labels, dim=1)

f1_scores = []

for c in range(10):
  positive_number = c

  tp = ((predictions==positive_number)&(test_labels==positive_number)).sum().float()
  fp = ((predictions==positive_number)&(test_labels!=positive_number)).sum().float()
  fn = ((predictions!=positive_number)&(test_labels==positive_number)).sum().float()
  tn = ((predictions!=positive_number)&(test_labels!=positive_number)).sum().float()

  precision = tp/(tp+fp+epsilon)
  recall = tp / (tp+fn+epsilon)
  f1_score = 2 * (precision * recall) / (precision + recall + epsilon)

  f1_scores.append(f1_score)

final_test_f1 = torch.stack(f1_scores).mean()
accuracy = (predictions==test_labels).float().mean()

print("\n--- Each Label's Accuracy ---")

for i in range(10):
  correct_predictions = ((predictions == i) & (test_labels == i)).sum().item()
  total_instances = (test_labels == i).sum().item()
  if total_instances > 0:
    acc = correct_predictions / total_instances * 100
    print(f"{i}'s Accuracy: {acc:.2f}%")
  else:
    print(f"{i}'s Accuracy: N/A (no instances of this label in test set)")

worst = (2, 7, 8, 9)

for i in worst:
    positive_number = i
    tp = ((predictions == positive_number) & (test_labels == positive_number)).sum().float()
    fp = ((predictions == positive_number) & (test_labels != positive_number)).sum().float()
    fn = ((predictions != positive_number) & (test_labels == positive_number)).sum().float()
    tn = ((predictions != positive_number) & (test_labels != positive_number)).sum().float()

    print(f"{i}'s score: Tp:{tp}, Tn:{tn}, Fp:{fp}, Fn:{fn}")
